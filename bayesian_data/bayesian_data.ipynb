{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    #plot_data(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "    sns.pairplot(data=data, hue='z')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partition(data):\n",
    "    X = data.drop(['z'], axis=1)\n",
    "    z = data['z']\n",
    "    partition = train_test_split(X, z, train_size=0.66)\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(filename, model, param):\n",
    "    data = read_data(filename)\n",
    "    partition = create_partition(data)\n",
    "    score = model(partition, param)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model(filename, model1, model2, param1, param2):\n",
    "    data = read_data(filename)\n",
    "    scores = []\n",
    "    for _ in range(100):\n",
    "        partition = create_partition(data)\n",
    "        score1 = model1(partition, param1)\n",
    "        score2 = model2(partition, param2)\n",
    "        scores.append(score1-score2)\n",
    "    return np.mean(scores)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gda(X_train, z_train):\n",
    "    categories = list(set(z_train))\n",
    "    prior = [np.mean(z_train==category) for category in categories]\n",
    "    exp = [np.mean(X_train[z_train==category]) for category in categories]\n",
    "    cov = [np.cov(X_train[z_train==category].T) for category in categories]\n",
    "    model = {\n",
    "        'categories': categories,\n",
    "        'prior': prior,\n",
    "        'exp': exp,\n",
    "        'cov': cov\n",
    "    }\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test):\n",
    "    nb_class = len(model['categories'])\n",
    "    pdf = [multivariate_normal.pdf(X_test, model['exp'][i], model['cov'][i], allow_singular=True) for i in range(nb_class)]\n",
    "    product = [model['prior'][i]*pdf[i] for i in range(nb_class)]\n",
    "    post = np.array([np.divide(product[i], sum(product), out=np.zeros_like(product[i]), where=sum(product)!=0) for i in range(nb_class)]).T\n",
    "    pred = [model['categories'][list(post[i]).index(max(post[i]))] for i in range(len(X_test))]\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predict(pred, X_test, z_test):\n",
    "    ax = sns.scatterplot(data=X_test, x='X1', y='X2', hue=pred, style=z_test)\n",
    "    leg_handles = ax.get_legend_handles_labels()[0]\n",
    "    ax.legend(leg_handles, ['pred1-test1', 'pred1-test2', 'pred2-test1', 'pred2-test2'], title='Legend')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gda(partition, param=None):\n",
    "    X_train, X_test, z_train, z_test = partition\n",
    "    model = train_gda(X_train, z_train)\n",
    "    pred = test(model, X_test)\n",
    "    score = accuracy_score(z_test, pred)\n",
    "    #plot_predict(pred, X_test, z_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_param(X, z, param):\n",
    "    param_grid = {'C': np.geomspace(10**-1, 10**1, 2)}\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    cv = GridSearchCV(LogisticRegression(max_iter=1000, solver=param['solver'], penalty=param['penalty']), param_grid, cv=3, scoring=\"accuracy\")\n",
    "    pipe = make_pipeline(poly, cv)\n",
    "    pipe.fit(X, z)\n",
    "    cv.fit(X, z)\n",
    "    param['C'] = cv.best_params_['C']\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pqlr(partition, param):\n",
    "    X_train, X_test, z_train, z_test = partition\n",
    "    if param['penalty']!='none':\n",
    "        param = compute_param(X_train, z_train, param)\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    model = LogisticRegression(max_iter=1000, C=param['C'], solver=param['solver'], penalty=param['penalty'])\n",
    "    pipe = make_pipeline(poly, model)\n",
    "    pipe.fit(X_train, z_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    score = accuracy_score(z_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_qlr = {\n",
    "   'solver': 'lbfgs',\n",
    "    'penalty': 'none',\n",
    "    'C': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9529411764705882"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score('data/synth.csv', gda, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9529411764705882"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score('data/synth.csv', pqlr, param_qlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017647058823529792"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_model('data/synth.csv', gda, pqlr, None, param_qlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rda(X_train, z_train, param):\n",
    "    mean = param['mean']\n",
    "    shrink = param['shrink']\n",
    "    scale = param['scale']\n",
    "    df = param['df']\n",
    "    categories = list(set(z_train))\n",
    "    nb_class = len(categories)\n",
    "    prior = [np.mean(z_train==category) for category in categories ]\n",
    "    \n",
    "    n = np.array([z_train[z_train==category].count() for category in categories])\n",
    "    exp_naive = np.array([np.mean(X_train[z_train==category]) for category in categories])\n",
    "    exp = [(n[i]*exp_naive[i]+shrink[i]*mean[i]) / (n[i]+shrink[i]) for i in range(nb_class)] \n",
    "    \n",
    "    cov_naive = np.array([np.cov(X_train[z_train==category].T) for category in categories])\n",
    "    denom = n + df + nb_class + 2\n",
    "    exp_dif = np.array([(exp_naive[i]-mean[i])*(exp_naive[i]-mean[i]).T for i in range(nb_class)])\n",
    "    scale_inv = np.array([np.linalg.inv(scale[i]) for i in range(nb_class)])\n",
    "    cov = [(n[i]*cov_naive[i] + (n[i]*shrink[i]/(n[i]+shrink[i])) * exp_dif[i] + scale_inv[i]) / denom[i] for i in range(nb_class)] \n",
    "    model = {\n",
    "        'categories': categories,\n",
    "        'prior': prior,\n",
    "        'exp': exp,\n",
    "        'cov': cov\n",
    "    }\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rda(partition, param):\n",
    "    X_train, X_test, z_train, z_test = partition\n",
    "    model = train_rda(X_train, z_train, param)\n",
    "    pred = test(model, X_test)\n",
    "    score = accuracy_score(z_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_pqlr = {\n",
    "   'solver': 'lbfgs',\n",
    "    'penalty': 'l2',\n",
    "    'C':1\n",
    "}\n",
    "\n",
    "param_rda = {\n",
    "    'mean': np.array([np.zeros(2), np.zeros(2)]),\n",
    "    'shrink': [0, 0],\n",
    "    'scale': [np.eye(2), np.eye(2)],\n",
    "    'df': [0, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558823529411765"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score('data/synth.csv', rda, param_rda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558823529411765"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score('data/synth.csv', pqlr, param_pqlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00038235294117646367"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_model('data/synth.csv', rda, pqlr, param_rda, param_pqlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
